
#
# SPCAfunction1Testing.txt
# 
#  Notes and code for 
#    running spca on KV1c dataset  


# July 26, 2022


#cd OncoSplice/sparsePCA
#ls -l


# ————————————————————————————————————————————————————————————————————————



# INSTALLATION
# Documentation lists following dependencies
#   numba
#   numpy
#   scipy
#   scikit-learn
#   matplotlib
#   pandas

#  pip install numba
#    might have already been installed, no issues noted
#  pip install scikit-dimension
#    no issues noted

# *  view installed package commands


 
# https://scikit-#. dimension.readthedocs.io/en/latest/quick_start.html

#  ------ SparsePCA online example ------------------

# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html#sklearn.decomposition.SparsePCA

# ————————————————————————————————————————————————————————————————————————

python3

# ----------   IMPORT DEPENDENCIES ----------------------

import sys,string,os
sys.path.append('/Users/schh5o/Library/Python/3.7/lib/python/site-packages')


#from sklearn import decomposition

import numpy as np
import pandas as pd
#
#from sklearn.decomposition import SparsePCA


# --------------  BRING IN KV1c DATASET W/ EVENT CODES ----------

# -- Bring in as pandas df

fn='kv1cMeanImputedPSIevcodes.txt'
data = pd.read_csv(fn,sep='\t',index_col=0)
#. index_col=0 sets uid as the index for the rows

# data.shape
# data.columns
# data.index

PSIdf = data.transpose()
#. conversion to np.array is done within SPCA function


parm_vec = { 'PCs' : 15, 's_alpha' : 0.8, 'it_tol' : 1e-04 , 'max_it' : 400 }
parm_vec = pd.Series(data=parm_vec)
type(parm_vec)
print(parm_vec)

from SPCAfunction1 import SPCA

df = PSIdf

eventsFromSPCA = SPCA( PSIdf=df, SPCAparms=parm_vec )
type(eventsFromSPCA)
eventsFromSPCA


##################################################################
#
# ******  SEE .py file for most recent version  *****
#
#  SPCAfunction1.txt
# 
#  SPCA function 
#    
# July 26, 2022
#
#  Performs Sparse PCA of numeric matrix using 
#  the SparsePCA function in sklearn-decomposition
# 
# **** SPCA function *******
#
def SPCA( PSIdf=None, SPCAparms=None ):
#
#   PSIdf is a pandas data frame with events (features) as columns, no missing values.  
#   So, PSI matrix may need to be transposed when calling this ftn.
#
#   Event names are assumed to be the row names, not in a column.
#
#   SPCAparms is a pandas series with entries for parameters (default value): 
#   nPCs (15), number of PCs to estimate
#   s_alpha (0.8), lasso loading shrinkage parameter (larger leads to sparser)
#   it_tol (1e-04), objective function convergence criterion value.
#   max_iter (400), maximum number of iterations.
#
#
    import numpy as np
    import pandas as pd
#
    from sklearn.decomposition import SparsePCA
#
# -- Make array with the event names/codes
#
    EVnames = np.array(PSIdf.columns.values)
#
# -- Mean-center each column (event)
#
    PSIdf = PSIdf - PSIdf.mean(axis=0)
#   chk=PSIdf.mean(axis=0)   #average by column
#   should be very small values, length=# of events
#

transformer1 = SparsePCA(n_components=int(parm_vec['PCs']), alpha=parm_vec['s_alpha'], ridge_alpha=0, max_iter=int(parm_vec['max_it']), tol=parm_vec['it_tol'], method='lars',verbose=True, random_state=0)
#
    PSInp = pd.DataFrame.to_numpy(PSIdf)
#
    transformer1.fit(PSInp)
#
# ------ further process the matrix of loadings
    res1=transformer1.components_
#   res1.shape
#
#   Identify events that have non-0 loading in >0 PCs
#   Binarize, then sum down columns
    res1[res1 != 0]=1
    event_sums = np.sum(res1,axis=0)
#
    res1TF=event_sums !=0
#
    keptEvents =  pd.Series( EVnames[res1TF] )
#
    return keptEvents


#################################################################

exit()




